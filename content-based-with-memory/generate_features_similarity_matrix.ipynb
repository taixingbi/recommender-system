{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/hh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "(451, 94)\n",
      "Index(['id', 'address', 'display_address', 'gAddress', 'geo_accuracy',\n",
      "       'street_address', 'house_num', 'street', 'city_id', 'state_id',\n",
      "       'zipcode', 'country_id', 'apt_num', 'bldg_id', 'is_rental', 'is_no_fee',\n",
      "       'is_furnished', 'is_commercial', 'listing_type', 'is_available',\n",
      "       'list_on_web', 'is_approved', 'available_on', 'status', 'headline',\n",
      "       'slug', 'description', 'pets', 'currency_id', 'rent',\n",
      "       'security_deposit', 'min_lease_term', 'max_lease_term', 'price',\n",
      "       'common_charges', 'real_estate_tax', 'taxes', 'maintenance',\n",
      "       'financing_allowed', 'show_price', 'commission', 'assessment',\n",
      "       'assessment_amount', 'assessment_date', 'assessment_expiration_date',\n",
      "       'assessment_pay_period', 'is_new_development', 'max_price',\n",
      "       'min_unit_area', 'max_unit_area', 'max_num_bedrooms', 'area_units',\n",
      "       'area', 'num_rooms', 'num_bedrooms', 'num_bathrooms', 'floor',\n",
      "       'lot_size_units', 'lot_size', 'exterior_sf', 'block', 'tax_lot',\n",
      "       'zoning', 'ownership_id', 'property_type_id', 'type_other',\n",
      "       'cross_street', 'neighborhood_id', 'region_id', 'show_house_num',\n",
      "       'show_apt_num', 'show_street', 'show_building_name',\n",
      "       'marketing_group_id', 'office_id', 'external_url', 'source',\n",
      "       'broker_id', 'comments', 'extra', 'listed_on', 'listed_by_agent_id',\n",
      "       'created_on', 'modified_on', 'created_by_agent_id',\n",
      "       'last_mod_by_agent_id', 'sort_score', 'last_scored', 'extra_keywords',\n",
      "       'meta_description', 'geo', 'rental_period', 'rental_registration',\n",
      "       'market_stage'],\n",
      "      dtype='object')\n",
      "googlenews model start loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             path_nsproperties_apt path_preTrained_wv_model\n",
      "                             path_save_features_matrix\n",
      "ipykernel_launcher.py: error: the following arguments are required: path_preTrained_wv_model, path_save_features_matrix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "googlenews model load done\n",
      "\n",
      "loading model time taken:  0:02:05.395117 h:m:s \n",
      "\n",
      "pipenv/tmp/headline.csv\n",
      "\n",
      "text training time taken:  0:02:56.428676 h:m:s \n",
      "\n",
      "pipenv/tmp/price.csv\n",
      "pipenv/tmp/financing_allowed.csv\n",
      "pipenv/tmp/rent.csv\n",
      "pipenv/tmp/area.csv\n",
      "pipenv/tmp/num_rooms.csv\n",
      "pipenv/tmp/num_bedrooms.csv\n",
      "pipenv/tmp/num_bathrooms.csv\n",
      "pipenv/tmp/common_charges.csv\n",
      "pipenv/tmp/lot_size.csv\n",
      "pipenv/tmp/is_rental.csv\n",
      "pipenv/tmp/show_price.csv\n",
      "pipenv/tmp/is_no_fee.csv\n",
      "pipenv/tmp/is_furnished.csv\n",
      "pipenv/tmp/is_commercial.csv\n",
      "pipenv/tmp/listing_type.csv\n",
      "pipenv/tmp/is_available.csv\n",
      "pipenv/tmp/list_on_web.csv\n",
      "pipenv/tmp/is_approved.csv\n",
      "pipenv/tmp/pets.csv\n",
      "pipenv/tmp/is_new_development.csv\n",
      "pipenv/tmp/geo.csv\n",
      "pipenv/tmp/apt_id.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#python generate_features_similarity_matrix.py \"data/nsproperties_apt_exclusive_is_available_list_on_web_nyc.csv\" 'data/GoogleNews-vectors-negative300.bin.gz' 'tmp/'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from shapely import wkb\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "import pipenv.text_similarity as text_sim #check pair_doc_similarity.py\n",
    "\n",
    "class apt_features_similarity():\n",
    "    def __init__(self, path_nsproperties_apt, path_preTrained_wv_model, path_save_features_matrix):\n",
    "        self.path_nsproperties_apt= path_nsproperties_apt\n",
    "        self.path_preTrained_wv_model= path_preTrained_wv_model\n",
    "        self.path_save_features_matrix= path_save_features_matrix\n",
    "        \n",
    "    def pipeline(self):\n",
    "        df= self.read_nsproperties_apt()\n",
    "        self.apt_features_sim(df)\n",
    "    \n",
    "    def read_nsproperties_apt(self):\n",
    "        df= pd.read_csv(self.path_nsproperties_apt, index_col = False)\n",
    "        #df= df[df['city_id']==1.0]# new york\n",
    "        print(df.shape)\n",
    "        #print all apt features\n",
    "        print(df.columns) \n",
    "        return df\n",
    "\n",
    "    def apt_features_sim(self, df):\n",
    "        def sim_text(class_text_sim, a, b):\n",
    "            if a and b:\n",
    "                try:\n",
    "                    score= class_text_sim.doc_similarity(a, b)\n",
    "                    return score\n",
    "                except:\n",
    "                    return np.nan\n",
    "            else: return np.nan         \n",
    "        \n",
    "        def sim_binary(a, b):\n",
    "            if a==np.nan or b==np.nan: return np.nan\n",
    "            if a==b:  return 1\n",
    "            if a!=b:  return 0 \n",
    "\n",
    "        def sim_continues(a, b):\n",
    "            # abs(a-b)/a: percent deviation\n",
    "            if a and b:  return 1 - ( abs(a-b)/a )\n",
    "            else: return np.nan\n",
    "        \n",
    "        def sim_location(a, b):\n",
    "            if a and b:\n",
    "                try:\n",
    "                    p1, p2= wkb.loads(a, hex=True), wkb.loads(b, hex=True)\n",
    "                    #p1.distance(p2): 2D distance\n",
    "                    nearby= 1-p1.distance(p2)\n",
    "                    return nearby\n",
    "                except: return np.nan\n",
    "            else: return np.nan\n",
    "        \n",
    "        def get_sim_matrix(df, col, category, path_save): #price\n",
    "            l= df[col].tolist()\n",
    "            n= len(l)\n",
    "            m = np.empty((n,n,))\n",
    "            m[:] = np.nan\n",
    "            \n",
    "            if category=='text':  \n",
    "                #loading word2vec pretained model for text similarity\n",
    "                class_text_sim= text_sim.pairDoc(self.path_preTrained_wv_model)\n",
    "                \n",
    "            for i in range(n): #row\n",
    "                for j in range(n): \n",
    "                    if category=='binary': m[i][j]= sim_binary(l[i], l[j])\n",
    "                    if category=='continues': m[i][j]= sim_continues(l[i], l[j])\n",
    "                    if category=='location': m[i][j]= sim_location(l[i], l[j])\n",
    "                    if category=='text': m[i][j]= sim_text(class_text_sim, l[i], l[j])\n",
    "                        \n",
    "            m[np.isnan(m)]= -0.0001\n",
    "            np.savetxt(path_save, m, delimiter=\",\")\n",
    "            #genfromtxt(path_save, delimiter=',') # numpy read array\n",
    "            return m\n",
    "\n",
    "        def generate_apt_sim_matrix(cols, category):\n",
    "            for col in cols:\n",
    "                path_save= self.path_save_features_matrix + col + '.csv'\n",
    "                get_sim_matrix(df, col, category, path_save) \n",
    "                print(path_save)\n",
    "        \n",
    "        def generate_apt_id(df):\n",
    "            path_save_index= self.path_save_features_matrix + 'apt_id.csv'\n",
    "            df.to_csv(path_save_index, index=False)\n",
    "            print(path_save_index)        \n",
    "        \n",
    "        features_binary= ['is_rental', 'show_price', 'is_no_fee', 'is_furnished', 'is_commercial', 'listing_type', 'is_available','list_on_web',\n",
    "         'is_approved', 'pets', 'is_new_development']\n",
    "        features_continues= ['price', 'financing_allowed', 'rent','area','num_rooms', 'num_bedrooms', \n",
    "        'num_bathrooms', 'common_charges', 'lot_size']   \n",
    "        features_loc= ['geo']\n",
    "        features_text= ['headline']        \n",
    "        \n",
    "        start_time= datetime.datetime.now()\n",
    "        generate_apt_sim_matrix(features_text, 'text')\n",
    "        print(\"\\ntext training time taken: \", (datetime.datetime.now()-start_time), \"h:m:s \\n\")\n",
    "        \n",
    "        generate_apt_sim_matrix(features_continues, 'continues')\n",
    "        generate_apt_sim_matrix(features_binary, 'binary')\n",
    "        generate_apt_sim_matrix(features_loc, 'location')    \n",
    "        generate_apt_id(df)\n",
    "  \n",
    "if __name__ == \"__main__\":       \n",
    "    \n",
    "    try:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('path_nsproperties_apt', help='input nsproperties_apt')\n",
    "        parser.add_argument('path_preTrained_wv_model', help='input path_preTrained_wv_model')        \n",
    "        parser.add_argument('path_save_features_matrix', help='output features matrix')    \n",
    "        args = parser.parse_args()\n",
    "\n",
    "        path_nsproperties_apt= args.path_nsproperties_apt\n",
    "        path_preTrained_wv_model= args.path_preTrained_wv_model\n",
    "        path_save_features_matrix= args.path_save_features_matrix \n",
    "        \n",
    "    except:    \n",
    "        path_nsproperties_apt= \"pipenv/data/nsproperties_apt_exclusive_is_available_list_on_web_nyc.csv\"\n",
    "        path_preTrained_wv_model= 'pipenv/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "        path_save_features_matrix= 'pipenv/tmp/'    \n",
    "    \n",
    "    apt_features_similarity(path_nsproperties_apt, path_preTrained_wv_model, path_save_features_matrix).pipeline()\n",
    "    print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
